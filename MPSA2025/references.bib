@inproceedings{albaugh_etal13,
  title = {The {{Automated Coding}} of {{Policy Agendas}}: {{A Dictionary-Based Approach}}},
  author = {Albaugh, Quinn and Sevenans, Julie and Soroka, Stuart and Loewen, Peter John},
  date = {2013-06-27},
  location = {Antwerp},
  abstract = {Until recently, the Policy Agendas community has focused on human coding texts using the policy agendas codebook. When researchers have needed to code more texts than is feasible or cost-effective, they have turned to machine learning methods. In contrast, we propose an automated dictionary-based content analysis approach for replicating the policy agendas codes for English and Dutch texts. We validate the dictionaries several ways. For the English-language dictionary, we use data from Prime Minister’s Question Time (from the United Kingdom) dataset and the State of the Union speeches (from the United States), both human-coded for each country’s respective codebooks. For the Dutch-language dictionary, we compare the results to media content and party manifestos from Belgium previously coded using the Policy Agendas codes. Results suggest that these two dictionaries may produce valid, reliable and comparable measures of policy agendas, and that may be is possible to create similar dictionaries for other languages.},
  eventtitle = {6th Annual {{Comparative Agendas Project}}},
  langid = {english},
  keywords = {Analyse textuelle,Dictionnaires},
  file = {/Users/jeremygilbert/Zotero/storage/49NT5DCS/Albaugh et al. - The Automated Coding of Policy Agendas A Dictionary-Based Approach.pdf}
}

@article{ansolabehere_iyengar94,
  title = {Riding the {{Wave}} and {{Claiming Ownership Over Issues}}: {{The Joint Effects}} of {{Advertising}} and {{News Coverage}} in {{Campaigns}}},
  shorttitle = {Riding the {{Wave}} and {{Claiming Ownership Over Issues}}},
  author = {Ansolabehere, Stephen and Iyengar, Shanto},
  date = {1994-23},
  journaltitle = {Public Opinion Quarterly},
  volume = {58},
  number = {3},
  pages = {335},
  issn = {0033362X},
  doi = {10.1086/269431},
  url = {https://academic.oup.com/poq/article-lookup/doi/10.1086/269431},
  urldate = {2024-12-03},
  abstract = {Using a realistic experimental design, this article tests two hypotheses concerning the relative effectiveness of campaign advertising. The first (issue-ownership) hypothesis predicts that candidates gain the most from advertising on issues over which they can claim "ownership." The second (riding-the-wave) hypothesis predicts that candidates are better off when they synchronize their advertising with news coverage. Our two studies yield support for the issue-ownership hypothesis, but no evidence of interactive effects between advertising and news.},
  langid = {english},
  keywords = {Electoral periods,Issue ownership,Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/QJUHFTKS/Ansolabehere et Iyengar - 1994 - Riding the Wave and Claiming Ownership Over Issues The Joint Effects of Advertising and News Covera.pdf}
}

@article{barbera_etal19,
  title = {Who {{Leads}}? {{Who Follows}}? {{Measuring Issue Attention}} and {{Agenda Setting}} by {{Legislators}} and the {{Mass Public Using Social Media Data}}},
  shorttitle = {Who {{Leads}}?},
  author = {Barberá, Pablo and Casas, Andreu and Nagler, Jonathan and Egan, Patrick J. and Bonneau, Richard and Jost, John T. and Tucker, Joshua A.},
  date = {2019-11},
  journaltitle = {American Political Science Review},
  shortjournal = {Am Polit Sci Rev},
  volume = {113},
  number = {4},
  pages = {883--901},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055419000352},
  url = {https://www.cambridge.org/core/product/identifier/S0003055419000352/type/journal_article},
  urldate = {2024-12-03},
  abstract = {Are legislators responsive to the priorities of the public? Research demonstrates a strong correspondence between the issues about which the public cares and the issues addressed by politicians, but conclusive evidence about who leads whom in setting the political agenda has yet to be uncovered. We answer this question with fine-grained temporal analyses of Twitter messages by legislators and the public during the 113th US Congress. After employing an unsupervised method that classifies tweets sent by legislators and citizens into topics, we use vector autoregression models to explore whose priorities more strongly predict the relationship between citizens and politicians. We find that legislators are more likely to follow, than to lead, discussion of public issues, results that hold even after controlling for the agenda-setting effects of the media. We also find, however, that legislators are more likely to be responsive to their supporters than to the general public.},
  langid = {english},
  keywords = {Electoral periods,Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/9PY84SEA/Barberá et al. - 2019 - Who Leads Who Follows Measuring Issue Attention and Agenda Setting by Legislators and the Mass Pub.pdf}
}

@article{benoit_etal16,
  title = {Crowd-Sourced {{Text Analysis}}: {{Reproducible}} and {{Agile Production}} of {{Political Data}}},
  shorttitle = {Crowd-Sourced {{Text Analysis}}},
  author = {Benoit, Kenneth and Conway, Drew and Lauderdale, Benjamin E. and Laver, Michael and Mikhaylov, Slava},
  date = {2016-05},
  journaltitle = {American Political Science Review},
  shortjournal = {Am Polit Sci Rev},
  volume = {110},
  number = {2},
  pages = {278--295},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055416000058},
  url = {https://www.cambridge.org/core/product/identifier/S0003055416000058/type/journal_article},
  urldate = {2024-11-08},
  abstract = {Empirical social science often relies on data that are not observed in the field, but are transformed into quantitative variables by expert researchers who analyze and interpret qualitative raw sources. While generally considered the most valid way to produce data, this expert-driven process is inherently difficult to replicate or to assess on grounds of reliability. Using crowd-sourcing to distribute text for reading and interpretation by massive numbers of non-experts, we generate results comparable to those using experts to read and interpret the same texts, but do so far more quickly and flexibly. Crucially, the data we collect can be reproduced and extended transparently, making crowd-sourced datasets intrinsically reproducible. This focuses researchers’ attention on the fundamental scientific objective of specifying reliable and replicable methods for collecting the data needed, rather than on the content of any particular dataset. We also show that our approach works straightforwardly with different types of political text, written in different languages. While findings reported here concern text analysis, they have far-reaching implications for expert-generated data in the social sciences.},
  langid = {english},
  keywords = {Crowd-sourcing},
  file = {/Users/jeremygilbert/Zotero/storage/8A5CDJIK/Benoit et al. - 2016 - Crowd-sourced Text Analysis Reproducible and Agile Production of Political Data.pdf}
}

@article{benoit_etal18,
  title = {Quanteda: {{An R}} Package for the Quantitative Analysis of Textual Data},
  shorttitle = {Quanteda},
  author = {Benoit, Kenneth and Watanabe, Kohei and Wang, Haiyan and Nulty, Paul and Obeng, Adam and Müller, Stefan and Matsuo, Akitaka},
  date = {2018-10-06},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {3},
  number = {30},
  pages = {774},
  issn = {2475-9066},
  doi = {10.21105/joss.00774},
  url = {http://joss.theoj.org/papers/10.21105/joss.00774},
  urldate = {2024-11-08},
  langid = {english},
  keywords = {Textual analysis},
  file = {/Users/jeremygilbert/Zotero/storage/I84S8KWS/Benoit et al. - 2018 - quanteda An R package for the quantitative analysis of textual data.pdf}
}

@incollection{bevan19,
  title = {Gone {{Fishing}}: {{The Creation}} of the {{Comparative Agendas Project Master Codebook}}},
  shorttitle = {Gone {{Fishing}}},
  booktitle = {Comparative {{Policy Agendas}}},
  author = {Bevan, Shaun},
  editor = {Baumgartner, Frank R. and Breunig, Christian and Grossman, Emiliano},
  date = {2019-03-14},
  edition = {1},
  pages = {17--34},
  publisher = {Oxford University PressOxford},
  doi = {10.1093/oso/9780198835332.003.0002},
  url = {https://academic.oup.com/book/11237/chapter/159761661},
  urldate = {2025-02-04},
  abstract = {Every data gathering effort is a story, often a horror story from the perspective of those that created it. This chapter presents a historical tale of the creation and logic behind the Comparative Agendas Project (CAP) Master Codebook. The CAP is in reality a network of many projects aimed at classifying political agendas according to the policies they address. However, with no central administration or common source of funding the original coding framework experienced noticeable drift based on the context of each project. To harmonize the data across projects I led the creation of a common Master Codebook that was only possible with the support of the CAP community. This paper further discusses the limitations of the CAP data. Ultimately the master coded CAP data presents a common way of understanding policy attention and provides the framework for more detailed work in and outside the CAP community.},
  isbn = {978-0-19-883533-2 978-0-19-187294-5},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/GFNRYC82/Bevan - 2019 - Gone Fishing The Creation of the Comparative Agendas Project Master Codebook.pdf}
}

@article{bilbao-jayo_almeida18,
  title = {Automatic Political Discourse Analysis with Multi-Scale Convolutional Neural Networks and Contextual Data},
  author = {Bilbao-Jayo, Aritz and Almeida, Aitor},
  date = {2018-11},
  journaltitle = {International Journal of Distributed Sensor Networks},
  shortjournal = {International Journal of Distributed Sensor Networks},
  volume = {14},
  number = {11},
  pages = {155014771881182},
  issn = {1550-1477, 1550-1477},
  doi = {10.1177/1550147718811827},
  url = {http://journals.sagepub.com/doi/10.1177/1550147718811827},
  urldate = {2024-12-19},
  abstract = {In this article, the authors propose a new approach to automate the analysis of the political discourse of the citizens and public servants, to allow public administrations to better react to their needs and claims. The tool presented in this article can be applied to the analysis of the underlying political themes in any type of text, in order to better understand the reasons behind it. To do so, the authors have built a discourse classifier using multi-scale convolutional neural networks in seven different languages: Spanish, Finnish, Danish, English, German, French, and Italian. Each of the language-specific discourse classifiers has been trained with sentences extracted from annotated parties’ election manifestos. The analysis proves that enhancing the multi-scale convolutional neural networks with context data improves the political analysis results.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/DT57PJ3B/Bilbao-Jayo et Almeida - 2018 - Automatic political discourse analysis with multi-scale convolutional neural networks and contextual.pdf}
}

@article{devlin_etal19,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019},
  journaltitle = {Proceedings of naacL-HLT},
  volume = {1},
  number = {2},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/VW2S4W8R/Devlin et al. - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf}
}

@article{do_etal22,
  title = {The {{Augmented Social Scientist}}: {{Using Sequential Transfer Learning}} to {{Annotate Millions}} of {{Texts}} with {{Human-Level Accuracy}}},
  shorttitle = {The {{Augmented Social Scientist}}},
  author = {Do, Salomé and Ollion, Étienne and Shen, Rubing},
  date = {2022-12-04},
  journaltitle = {Sociological Methods \& Research},
  shortjournal = {Sociological Methods \& Research},
  volume = {53},
  number = {3},
  pages = {1167--1200},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/00491241221134526},
  url = {https://journals.sagepub.com/doi/10.1177/00491241221134526},
  urldate = {2025-02-08},
  abstract = {The last decade witnessed a spectacular rise in the volume of available textual data. With this new abundance came the question of how to analyze it. In the social sciences, scholars mostly resorted to two well-established approaches, human annotation on sampled data on the one hand (either performed by the researcher, or outsourced to microworkers), and quantitative methods on the other. Each approach has its own merits - a potentially very fine-grained analysis for the former, a very scalable one for the latter - but the combination of these two properties has not yielded highly accurate results so far. Leveraging recent advances in sequential transfer learning, we demonstrate via an experiment that an expert can train a precise, efficient automatic classifier in a very limited amount of time. We also show that, under certain conditions, expert-trained models produce better annotations than humans themselves. We demonstrate these points using a classic research question in the sociology of journalism, the rise of a “horse race” coverage of politics. We conclude that recent advances in transfer learning help us augment ourselves when analyzing unstructured data.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/B3IHK3UG/Do et al. - 2024 - The Augmented Social Scientist Using Sequential Transfer Learning to Annotate Millions of Texts wit.pdf}
}

@online{dong_etal23,
  title = {Probing {{Explicit}} and {{Implicit Gender Bias}} through {{LLM Conditional Text Generation}}},
  author = {Dong, Xiangjue and Wang, Yibo and Yu, Philip S. and Caverlee, James},
  date = {2023-11-01},
  eprint = {2311.00306},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.00306},
  url = {http://arxiv.org/abs/2311.00306},
  urldate = {2023-12-23},
  abstract = {Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which are challenging to be comprehensively collected and are limited to explicit bias evaluation. In addition, we believe that instances devoid of gender-related language or explicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in this work, we propose a conditional text generation mechanism without the need for predefined gender phrases and stereotypes. This approach employs three types of inputs generated through three distinct strategies to probe LLMs, aiming to show evidence of explicit and implicit gender biases in LLMs. We also utilize explicit and implicit evaluation metrics to evaluate gender bias in LLMs under different strategies. Our experiments demonstrate that an increased model size does not consistently lead to enhanced fairness and all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.},
  pubstate = {prepublished},
  file = {/Users/jeremygilbert/Zotero/storage/PMSPZTG8/Dong et al. - 2023 - Probing Explicit and Implicit Gender Bias through .pdf;/Users/jeremygilbert/Zotero/storage/4477DAL9/2311.html}
}

@article{dunmire12,
  title = {Political {{Discourse Analysis}}: {{Exploring}} the {{Language}} of {{Politics}} and the {{Politics}} of {{Language}}},
  shorttitle = {Political {{Discourse Analysis}}},
  author = {Dunmire, Patricia L.},
  date = {2012-11},
  journaltitle = {Language and Linguistics Compass},
  shortjournal = {Language and Linguist. Compass},
  volume = {6},
  number = {11},
  pages = {735--751},
  issn = {1749-818X, 1749-818X},
  doi = {10.1002/lnc3.365},
  url = {https://compass.onlinelibrary.wiley.com/doi/10.1002/lnc3.365},
  urldate = {2024-12-19},
  abstract = {This essay overviews the body of research known as political discourse analysis (PDA). I begin by situating this work within the linguistic and political turns that took place in the latter part of the 20th century within the human and social sciences. I then discuss different conceptions of what comprises the political and the appropriate objects of study for PDA. Adopting an inclusive conception of politics and discourse, I consider the relationship between PDA and critical discourse analysis (CDA). I close with a review of studies of political discourse in terms of their theoretical and analytic frameworks and the socio-political issues they address.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/VEW7CKGR/Dunmire - 2012 - Political Discourse Analysis Exploring the Language of Politics and the Politics of Language.pdf}
}

@article{duval_petry16,
  title = {L'analyse automatisée du ton médiatique : construction et utilisation de la version française du \mkbibemph{Lexicoder Sentiment Dictionary}},
  shorttitle = {L'analyse automatisée du ton médiatique},
  author = {Duval, Dominic and Pétry, François},
  date = {2016-06},
  journaltitle = {Canadian Journal of Political Science},
  shortjournal = {Can J Pol Sci},
  volume = {49},
  number = {2},
  pages = {197--220},
  issn = {0008-4239, 1744-9324},
  doi = {10.1017/S000842391600055X},
  url = {https://www.cambridge.org/core/product/identifier/S000842391600055X/type/journal_article},
  urldate = {2025-02-08},
  abstract = {This article introduces a new dictionary for the automated analysis of the tone of French media. We named it the French Lexicoder Sentiment Dictionary \{LSDFr) in reference to the English lexicon developed by Young and Soroka (2012), the Lexicoder Sentiment Dictionary (LSD), from which the LSDFr was built. We compare the LSDFr to the only other French sentiment lexicon, Linguistic Inquiry and Word Count (LIWC). First, we detail the construction of the dictio nary. We then test the internal validity of the LSDFr comparing it with a corpus of manually coded texts. Finally, we test the external validity of LSDFr by measuring how the media tone, calculated using our dictionary, predicts voting intentions in the last four Quebec elections. Our goal is to enable other researchers to conduct media analyses with a comparable corpus of texts in French.\vphantom\}},
  langid = {french},
  file = {/Users/jeremygilbert/Zotero/storage/QRN4WSRQ/Duval et Pétry - 2016 - L'analyse automatisée du ton médiatique  construction et utilisation de la version française du .pdf}
}

@book{entman04a,
  title = {Projections of {{Power}}: {{Framing News}}, {{Public Opinion}}, and {{U}}.{{S}}. {{Foreign Policy}}},
  shorttitle = {Projections of {{Power}}},
  author = {Entman, Robert M.},
  date = {2004},
  eprint = {SzG0HkZeoNIC},
  eprinttype = {googlebooks},
  publisher = {University of Chicago Press},
  abstract = {To succeed in foreign policy, U.S. presidents have to sell their versions or framings of political events to the news media and to the public. But since the end of the Cold War, journalists have increasingly resisted presidential views, even offering their own spin on events. What, then, determines whether the media will accept or reject the White House perspective? And what consequences does this new media environment have for policymaking and public opinion?  To answer these questions, Robert M. Entman develops a powerful new model of how media framing works—a model that allows him to explain why the media cheered American victories over small-time dictators in Grenada and Panama but barely noticed the success of far more difficult missions in Haiti and Kosovo. Discussing the practical implications of his model, Entman also suggests ways to more effectively encourage the exchange of ideas between the government and the media and between the media and the public. His book will be an essential guide for political scientists, students of the media, and anyone interested in the increasingly influential role of the media in foreign policy.},
  isbn = {978-0-226-21073-5},
  langid = {english},
  pagetotal = {241},
  keywords = {Political Science / General}
}

@article{entman93,
  title = {Framing: {{Toward Clarification}} of a {{Fractured Paradigm}}},
  shorttitle = {Framing},
  author = {Entman, Robert M.},
  date = {1993-12-01},
  journaltitle = {Journal of Communication},
  volume = {43},
  number = {4},
  pages = {51--58},
  issn = {0021-9916, 1460-2466},
  doi = {10.1111/j.1460-2466.1993.tb01304.x},
  url = {https://academic.oup.com/joc/article/43/4/51-58/4160153},
  urldate = {2024-12-20},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/9FZEYKUX/Entman - 1993 - Framing Toward Clarification of a Fractured Paradigm.pdf}
}

@book{esser_stromback14,
  title = {Mediatization of {{Politics}}},
  editor = {Esser, Frank and Strömbäck, Jesper},
  date = {2014},
  publisher = {Palgrave Macmillan UK},
  location = {London},
  doi = {10.1057/9781137275844},
  url = {http://link.springer.com/10.1057/9781137275844},
  urldate = {2024-12-03},
  isbn = {978-1-137-42597-3 978-1-137-27584-4},
  langid = {english},
  keywords = {Medias agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/BZH9WD66/Esser et Strömbäck - 2014 - Mediatization of Politics.pdf}
}

@online{ferdaus_etal24,
  title = {Towards {{Trustworthy AI}}: {{A Review}} of {{Ethical}} and {{Robust Large Language Models}}},
  shorttitle = {Towards {{Trustworthy AI}}},
  author = {Ferdaus, Md Meftahul and Abdelguerfi, Mahdi and Ioup, Elias and Niles, Kendall N. and Pathak, Ken and Sloan, Steven},
  date = {2024-06-01},
  eprint = {2407.13934},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.13934},
  url = {http://arxiv.org/abs/2407.13934},
  urldate = {2025-03-19},
  abstract = {The rapid advancements in Large Language Models (LLMs) have the potential to revolutionize various domains, but their swift progression presents significant challenges in terms of oversight, ethical development, and establishing user trust. This comprehensive review examines the critical trust issues in LLMs, focusing on concerns such as unintentional harms, lack of transparency, vulnerability to attacks, alignment with human values, and environmental impact. We highlight the numerous obstacles that can undermine user trust, including societal biases, lack of transparency in decision-making, potential for misuse, and challenges with rapidly evolving technology. Addressing these trust gaps is vital as LLMs become more prevalent in sensitive domains like finance, healthcare, education, and policy.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  file = {/Users/jeremygilbert/Zotero/storage/M9VJXQZU/Ferdaus et al. - 2024 - Towards Trustworthy AI A Review of Ethical and Robust Large Language Models.pdf}
}

@article{giasson_dubois18,
  title = {Juste part, boycott et loi spéciale. Le cadrage gouvernemental d'un printemps de crise sociale},
  author = {Giasson, Thierry and Dubois, Philippe},
  date = {2018-12},
  journaltitle = {Canadian Journal of Political Science},
  shortjournal = {Can J Pol Sci},
  volume = {51},
  number = {4},
  pages = {837--859},
  issn = {0008-4239, 1744-9324},
  doi = {10.1017/S0008423918000513},
  url = {https://www.cambridge.org/core/product/identifier/S0008423918000513/type/journal_article},
  urldate = {2024-12-19},
  abstract = {This article examines how the government framed its communications during the socalled "Printemps érable" (Maple Spring), a historic student protest movement that took place in Quebec in 2012. Six years after the end of the conflict, and despite the production of a significant volume of analysis and reflections on this social crisis, no empirical work had been dedicated yet to the study of the government’s communication strategy. Following a quantitative content analysis of 424 public interventions from cabinet members, this study raises the argumentative frameworks at the heart of the government’s communication strategy. Drawing on Entman’s cascading activation model (2004), the analysis shows how the government tried to define the problems, solutions and protagonists involved in this societal conflict. Our study highlights the government’s failure to maintain the framing initiative of the crisis, and the change in communication strategy that resulted.},
  langid = {french},
  file = {/Users/jeremygilbert/Zotero/storage/YZHL7NPX/Giasson et Dubois - 2018 - Juste part, boycott et loi spéciale. Le cadrage gouvernemental d'un printemps de crise sociale.pdf}
}

@article{gilardi_etal22,
  title = {Social {{Media}} and {{Political Agenda Setting}}},
  author = {Gilardi, Fabrizio and Gessler, Theresa and Kubli, Maël and Müller, Stefan},
  date = {2022-01-02},
  journaltitle = {Political Communication},
  shortjournal = {Political Communication},
  volume = {39},
  number = {1},
  pages = {39--60},
  issn = {1058-4609, 1091-7675},
  doi = {10.1080/10584609.2021.1910390},
  url = {https://www.tandfonline.com/doi/full/10.1080/10584609.2021.1910390},
  urldate = {2024-12-03},
  abstract = {What is the role of social media in political agenda setting? Digital platforms have reduced the gatekeeping power of traditional media and, potentially, they have increased the capacity of various kinds of actors to shape the agenda. We study this question in the Swiss context by examining the connections between three agendas: the traditional media agenda, the social media agenda of parties, and the social media agenda of politicians. Specifically, we validate and apply supervised machine learning classifiers to categorize 2.78 million articles published in 84 newspapers, 6,500 tweets posted on official party accounts, and 210,000 tweets posted by politicians on their own accounts from January 2018 until December 2019. We first use the classifier to measure the salience of the four most relevant issues of the period: the environment, Europe, gender equality, and immigration. Then, using a vector autoregression (VAR) approach, we analyze the relationship between the three agendas. Results show that not only do the traditional media agenda, the social media agenda of parties, and the social media agenda of politicians influence one another but, overall, no agenda leads the others more than it is led by them. There is one important exception: for the environment issue, the social media agenda of parties is more predictive of the traditional media agenda than vice-versa. These findings underscore how closely different agendas are tied together, but also show that advocacy campaigns may play an important role in both constraining and enabling parties to push their specific agendas.},
  langid = {english},
  keywords = {Parties effect on media,Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/ZMY9XMTB/Gilardi et al. - 2022 - Social Media and Political Agenda Setting.pdf}
}

@article{gilardi_etal23,
  title = {{{ChatGPT}} Outperforms Crowd Workers for Text-Annotation Tasks},
  author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
  date = {2023-07-25},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {120},
  number = {30},
  pages = {e2305016120},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2305016120},
  url = {https://pnas.org/doi/10.1073/pnas.2305016120},
  urldate = {2024-12-09},
  abstract = {Many NLP applications require manual text annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using four samples of tweets and news articles (               n               = 6,183), we show that ChatGPT outperforms crowd workers for several annotation tasks, including relevance, stance, topics, and frame detection. Across the four datasets, the zero-shot accuracy of ChatGPT exceeds that of crowd workers by about 25 percentage points on average, while ChatGPT’s intercoder agreement exceeds that of both crowd workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than \$0.003—about thirty times cheaper than MTurk. These results demonstrate the potential of large language models to drastically increase the efficiency of text classification.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/NFTIBGEV/Gilardi et al. - 2023 - ChatGPT outperforms crowd workers for text-annotation tasks.pdf}
}

@article{green-pedersen_mortensen10,
  title = {Who Sets the Agenda and Who Responds to It in the {{Danish}} Parliament? {{A}} New Model of Issue Competition and Agenda‐setting},
  shorttitle = {Who Sets the Agenda and Who Responds to It in the {{Danish}} Parliament?},
  author = {Green‐Pedersen, Christoffer and Mortensen, Peter B.},
  date = {2010-03},
  journaltitle = {European Journal of Political Research},
  shortjournal = {European J Political Res},
  volume = {49},
  number = {2},
  pages = {257--281},
  issn = {0304-4130, 1475-6765},
  doi = {10.1111/j.1475-6765.2009.01897.x},
  url = {https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.2009.01897.x},
  urldate = {2024-12-03},
  abstract = {Inspired by the agenda-setting literature, this article outlines a model of issue competition focusing on the interaction between government and opposition parties through the party-system agenda. Unlike previous studies of issue competition, the model makes it possible to answer questions such as why some parties have greater success than others in forcing other parties to address unpleasant issues. One of the central implications of the model is that opposition parties are freer to focus continually on issues that are advantageous to themselves, whereas government parties more often are forced to respond to issues brought up on the party-system agenda. Using data on issue competition in Denmark covering 25 years and 23 issue categories, the issue competition model is evaluated and finds strong support in a set of cross-sectional time-series analyses.},
  langid = {english},
  keywords = {Parties adaptation on media,Political agenda-setting,Vote seeking},
  file = {/Users/jeremygilbert/Zotero/storage/2MAJH268/Green‐Pedersen et Mortensen - 2010 - Who sets the agenda and who responds to it in the Danish parliament A new model of issue competitio.pdf}
}

@article{green-pedersen_stubager10,
  title = {The {{Political Conditionality}} of {{Mass Media Influence}}: {{When Do Parties Follow Mass Media Attention}}?},
  shorttitle = {The {{Political Conditionality}} of {{Mass Media Influence}}},
  author = {Green-Pedersen, Christoffer and Stubager, Rune},
  date = {2010-07},
  journaltitle = {British Journal of Political Science},
  shortjournal = {Brit. J. Polit. Sci.},
  volume = {40},
  number = {3},
  pages = {663--677},
  issn = {0007-1234, 1469-2112},
  doi = {10.1017/S0007123410000037},
  url = {https://www.cambridge.org/core/product/identifier/S0007123410000037/type/journal_article},
  urldate = {2024-12-03},
  abstract = {Claims regarding the power of the mass media in contemporary politics are much more frequent than research actually analysing the influence of mass media on politics. Building upon the notion of issue ownership, this article argues that the capacity of the mass media to influence the respective agendas of political parties is conditioned upon the interests of the political parties. Media attention to an issue generates attention from political parties when the issue is one that political parties have an interest in politicizing in the first place. The argument of the article is supported in a time-series study of mass media influence on the opposition parties’ agenda in Denmark over a twenty-year period.},
  langid = {english},
  keywords = {Parties adaptation on media},
  file = {/Users/jeremygilbert/Zotero/storage/TDPERUTQ/Green-Pedersen et Stubager - 2010 - The Political Conditionality of Mass Media Influence When Do Parties Follow Mass Media Attention.pdf}
}

@article{grimmer_stewart13,
  title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{Automatic Content Analysis Methods}} for {{Political Texts}}},
  shorttitle = {Text as {{Data}}},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  date = {2013},
  journaltitle = {Political Analysis},
  shortjournal = {Polit. anal.},
  volume = {21},
  number = {3},
  pages = {267--297},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mps028},
  url = {https://www.cambridge.org/core/product/identifier/S1047198700013401/type/journal_article},
  urldate = {2024-12-09},
  abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/PXQH7ZC7/Grimmer et Stewart - 2013 - Text as Data The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts.pdf}
}

@book{iyengar_kinder87,
  title = {News {{That Matters}}: {{Television}} \& {{American Opinion}}},
  shorttitle = {News {{That Matters}}},
  author = {Iyengar, Shanto and Kinder, Donald R.},
  date = {1987},
  eprint = {SH_T0RLDJaUC},
  eprinttype = {googlebooks},
  publisher = {University of Chicago Press},
  abstract = {Almost twenty-five years ago, Shanto Iyengar and Donald R. Kinder first documented a series of sophisticated and innovative experiments that unobtrusively altered the order and emphasis of news stories in selected television broadcasts.~ Their resulting book News That Matters, now hailed as a classic by scholars of political science and public opinion alike, is here updated for the twenty-first century, with a new preface and epilogue by the authors. Backed by careful analysis of public opinion surveys, the authors show how, despite changing American politics, those issues that receive extended coverage in the national news become more important to viewers, while those that are ignored lose credibility. Moreover, those issues that are prominent in the news stream continue to loom more heavily as criteria for evaluating the president and for choosing between political candidates.“News That Matters does matter, because it demonstrates conclusively that television newscasts powerfully affect opinion. . . . All that follows, whether it supports, modifies, or challenges their conclusions, will have to begin here.”—The Public Interest},
  isbn = {978-0-226-38860-1},
  langid = {english},
  pagetotal = {214},
  keywords = {Medias agenda-setting}
}

@book{iyengar94,
  title = {Is {{Anyone Responsible}}?: {{How Television Frames Political Issues}}},
  shorttitle = {Is {{Anyone Responsible}}?},
  author = {Iyengar, Shanto},
  date = {1994-08-17},
  eprint = {Ca6VaTItqi4C},
  eprinttype = {googlebooks},
  publisher = {University of Chicago Press},
  abstract = {A disturbingly cautionary tale, Is Anyone Responsible? anchors with powerful evidence suspicions about the way in which television has impoverished political discourse in the United States and at the same time molds American political consciousness. It is essential reading for media critics, psychologists, political analysts, and all the citizens who want to be sure that their political opinions are their own.  "Not only does it provide convincing evidence for particular effects of media fragmentation, but it also explores some of the specific mechanisms by which television works its damage. . . . Here is powerful additional evidence for those of us who like to flay television for its contributions to the trivialization of public discourse and the erosion of democratic accountability."—William A. Gamson, Contemporary Sociology  "Iyengar's book has substantial merit. . . . [His] experimental methods offer a precision of measurement that media effects research seldom attains. I believe, moreover, that Iyengar's notion of framing effects is one of the truly important theoretical concepts to appear in recent years."—Thomas E. Patterson, American Political Science Review},
  isbn = {978-0-226-38853-3},
  langid = {english},
  pagetotal = {207},
  keywords = {Political agenda-setting}
}

@article{kennedy_etal20,
  title = {The Shape of and Solutions to the {{MTurk}} Quality Crisis},
  author = {Kennedy, Ryan and Clifford, Scott and Burleigh, Tyler and Waggoner, Philip D. and Jewell, Ryan and Winter, Nicholas J. G.},
  date = {2020-10},
  journaltitle = {Political Science Research and Methods},
  shortjournal = {PSRM},
  volume = {8},
  number = {4},
  pages = {614--629},
  issn = {2049-8470, 2049-8489},
  doi = {10.1017/psrm.2020.6},
  url = {https://www.cambridge.org/core/product/identifier/S2049847020000060/type/journal_article},
  urldate = {2025-02-09},
  abstract = {Amazon’s Mechanical Turk is widely used for data collection; however, data quality may be declining due to the use of virtual private servers to fraudulently gain access to studies. Unfortunately, we know little about the scale and consequence of this fraud, and tools for social scientists to detect and prevent this fraud are underdeveloped. We first analyze 38 studies and show that this fraud is not new, but has increased recently. We then show that these fraudulent respondents provide particularly low-quality data and can weaken treatment effects. Finally, we provide two solutions: an easy-to-use application for identifying fraud in the existing datasets and a method for blocking fraudulent respondents in Qualtrics surveys.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/BDTI845T/Kennedy et al. - 2020 - The shape of and solutions to the MTurk quality crisis.pdf}
}

@article{king95,
  title = {Replication, {{Replication}}},
  author = {King, Gary},
  date = {1995},
  journaltitle = {Political Science \& Politics},
  volume = {28},
  number = {3},
  pages = {444--452},
  file = {/Users/jeremygilbert/Zotero/storage/UKHD8HPD/King - 1995 - Replication, Replication.pdf}
}

@incollection{lang_lang16,
  title = {Watergate: {{An}} Exploration of the Agenda-Building Process},
  booktitle = {Agenda {{Setting}}},
  author = {Lang, Gladys Engel and Lang, Kurt},
  date = {2016},
  pages = {277--289},
  publisher = {Routledge},
  keywords = {Parties effect on media}
}

@article{lauderdale_herzog16a,
  title = {Measuring {{Political Positions}} from {{Legislative Speech}}},
  author = {Lauderdale, Benjamin E. and Herzog, Alexander},
  date = {2016},
  journaltitle = {Political Analysis},
  shortjournal = {Polit. anal.},
  volume = {24},
  number = {3},
  pages = {374--394},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpw017},
  url = {https://www.cambridge.org/core/product/identifier/S1047198700014091/type/journal_article},
  urldate = {2024-12-09},
  abstract = {Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. We demonstrate the first viable approach for estimating legislator-specific scores from the entire speech corpus of a legislature, while also producing extensive information about the evolution of speech polarization and politically loaded language. In the Irish Dáil, we show that the dominant dimension of speech variation is government–opposition, with ministers more extreme on this dimension than backbenchers, and a second dimension distinguishing between the establishment and anti-establishment opposition parties. In the U. S. Senate, we estimate a dimension that has moderate within-party correlations with scales based on roll-call votes and campaign donation patterns; however, we observe greater overlap across parties in speech positions than roll-call positions and partisan polarization in speeches varies more clearly in response to major political events.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/C5LTGEKE/Lauderdale et Herzog - 2016 - Measuring Political Positions from Legislative Speech.pdf}
}

@article{laver_etal03,
  title = {Extracting {{Policy Positions}} from {{Political Texts Using Words}} as {{Data}}},
  author = {Laver, Michael and Benoit, Kenneth and Garry, John},
  date = {2003-05},
  journaltitle = {American Political Science Review},
  shortjournal = {Am. Pol. Sci. Rev.},
  volume = {97},
  number = {02},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055403000698},
  url = {http://www.journals.cambridge.org/abstract_S0003055403000698},
  urldate = {2024-12-11},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/B7DCRABD/Laver et al. - 2003 - Extracting Policy Positions from Political Texts Using Words as Data.pdf}
}

@article{laver_garry00,
  title = {Estimating {{Policy Positions}} from {{Political Texts}}},
  author = {Laver, Michael and Garry, John},
  date = {2000-07},
  journaltitle = {American Journal of Political Science},
  shortjournal = {American Journal of Political Science},
  volume = {44},
  number = {3},
  eprint = {2669268},
  eprinttype = {jstor},
  pages = {619},
  issn = {00925853},
  doi = {10.2307/2669268},
  url = {https://www.jstor.org/stable/2669268?origin=crossref},
  urldate = {2024-12-19},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/37HGWN47/Laver et Garry - 2000 - Estimating Policy Positions from Political Texts.pdf}
}

@article{lawlor_tolley17,
  title = {Deciding {{Who}}’s {{Legitimate}}: {{News Media Framing}} of {{Immigrants}} and {{Refugees}}},
  author = {Lawlor, Andrea and Tolley, Erin},
  date = {2017},
  journaltitle = {International Journal of Communication},
  volume = {11},
  pages = {967--991},
  abstract = {With its relatively high immigration levels and comparatively favorable public opinion, Canada is often seen as a bastion of support for immigrants and refugees. We argue that support is uneven because Canadians differentiate between economic immigrants and those who arrive on humanitarian grounds. Our conclusion is supported by an automated content analysis of Canadian print media coverage over a 10-year period, an approach that allowed us to capture a wide swath of discourse. We found distinct differences in the framing of immigrants and refugees. Immigrants are framed in economic terms, whereas greater attention is focused on the validity of refugee claims, potential security threats, and the extent to which refugees “take advantage” of social programs. More focus is also given to refugees’ national origins, and that framing is disproportionately negative. Our analysis illustrates the discursive distinctions that are drawn between immigrants and refugees and the hierarchy of preferences for the former over the latter.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/8TX7BDTV/Lawlor - Deciding Who’s Legitimate News Media Framing of Immigrants and Refugees.pdf}
}

@article{linegar_etal23,
  title = {Large Language Models and Political Science},
  author = {Linegar, Mitchell and Kocielnik, Rafal and Alvarez, R. Michael},
  date = {2023-10-16},
  journaltitle = {Frontiers in Political Science},
  shortjournal = {Front. Polit. Sci.},
  volume = {5},
  pages = {1257092},
  issn = {2673-3145},
  doi = {10.3389/fpos.2023.1257092},
  url = {https://www.frontiersin.org/articles/10.3389/fpos.2023.1257092/full},
  urldate = {2024-12-09},
  abstract = {Large Language Models (LLMs) are a type of artificial intelligence that uses information from very large datasets to model the use of language and generate content. While LLMs like GPT-3 have been used widely in many applications, the recent public release of OpenAI's ChatGPT has opened more debate about the potential uses and abuses of LLMs. In this paper, we provide a brief introduction to LLMs and discuss their potential application in political science and political methodology. We use two examples of LLMs from our recent research to illustrate how LLMs open new areas of research. We conclude with a discussion of how researchers can use LLMs in their work, and issues that researchers need to be aware of regarding using LLMs in political science and political methodology.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/G8RJQHZ4/Linegar et al. - 2023 - Large language models and political science.pdf}
}

@book{lippmann22,
  title = {Public Opinion},
  author = {Lippmann, Walter},
  date = {1922},
  publisher = {Transaction Publishers},
  isbn = {978-1-56000-999-3},
  langid = {english},
  keywords = {Medias agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/4EHBUGN4/Lippmann - 1998 - Public opinion.pdf}
}

@article{lowe_etal11,
  title = {Scaling {{Policy Preferences}} from {{Coded Political Texts}}},
  author = {Lowe, Will and Benoit, Kenneth and Mikhaylov, Slava and Laver, Michael},
  date = {2011-02},
  journaltitle = {Legislative Studies Quarterly},
  shortjournal = {Legislative Studies Qtrly},
  volume = {36},
  number = {1},
  pages = {123--155},
  issn = {0362-9805, 1939-9162},
  doi = {10.1111/j.1939-9162.2010.00006.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1939-9162.2010.00006.x},
  urldate = {2024-12-08},
  abstract = {Scholars estimating policy positions from political texts typically code words or sentences and then build left‐right policy scales based on the relative frequencies of text units coded into different categories. Here we reexamine such scales and propose a theoretically and linguistically superior alternative based on the logarithm of odds‐ratios. We contrast this scale with the current approach of the Comparative Manifesto Project (CMP), showing that our proposed logit scale avoids widely acknowledged flaws in previous approaches. We validate the new scale using independent expert surveys. Using existing CMP data, we show how to estimate more distinct policy dimensions, for more years, than has been possible before, and make this dataset publicly available. Finally, we draw some conclusions about the future design of coding schemes for political texts.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/YDH4IVYH/Lowe et al. - 2011 - Scaling Policy Preferences from Coded Political Texts.pdf}
}

@inproceedings{martin_etal20,
  title = {{{CamemBERT}}: A {{Tasty French Language Model}}},
  shorttitle = {{{CamemBERT}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Martin, Louis and Muller, Benjamin and Suárez, Pedro Javier Ortiz and Dupont, Yoann and Romary, Laurent and family=Clergerie, given=Éric Villemonte, prefix=de la, useprefix=false and Seddah, Djamé and Sagot, Benoît},
  date = {2020},
  eprint = {1911.03894},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {7203--7219},
  doi = {10.18653/v1/2020.acl-main.645},
  url = {http://arxiv.org/abs/1911.03894},
  urldate = {2025-02-08},
  abstract = {Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models—in all languages except English—very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/jeremygilbert/Zotero/storage/7USVWZRZ/Martin et al. - 2020 - CamemBERT a Tasty French Language Model.pdf}
}

@article{mazzoleni_schulz99,
  title = {"{{Mediatization}}" of {{Politics}}: {{A Challenge}} for {{Democracy}}?},
  shorttitle = {"{{Mediatization}}" of {{Politics}}},
  author = {Mazzoleni, Gianpietro and Schulz, Winfried},
  date = {1999-07},
  journaltitle = {Political Communication},
  shortjournal = {Political Communication},
  volume = {16},
  number = {3},
  pages = {247--261},
  issn = {1058-4609, 1091-7675},
  doi = {10.1080/105846099198613},
  url = {http://www.tandfonline.com/doi/abs/10.1080/105846099198613},
  urldate = {2024-12-03},
  abstract = {The growing intrusion of media into the political domain in many countries has led critics to worry about the approach of the “media-driven republic,” in which mass media will usurp the functions of political institutions in the liberal state. However, close inspection of the evidence reveals that political institutions in many nations have retained their functions in the face of expanded media power. The best description of the current situation is “mediatization,” where political institutions increasingly are dependent on and shaped by mass media but nevertheless remain in control of political processes and functions.},
  langid = {english},
  keywords = {Medias effect on parties},
  file = {/Users/jeremygilbert/Zotero/storage/JE4GCZ3A/Mazzoleni et Schulz - 1999 - Mediatization of Politics A Challenge for Democracy.pdf}
}

@article{mccombs_shaw72,
  title = {The {{Agenda-Setting Function}} of {{Mass Media}}},
  author = {McCombs, Maxwell E. and Shaw, Donald L.},
  date = {1972},
  journaltitle = {Public Opinion Quarterly},
  volume = {36},
  number = {2},
  pages = {176},
  publisher = {Oxford University Press (OUP)},
  issn = {0033-362X},
  doi = {10.1086/267990},
  url = {https://academic.oup.com/poq/article-lookup/doi/10.1086/267990},
  urldate = {2024-09-16},
  langid = {english},
  keywords = {Medias agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/Q3XMHA94/McCombs et Shaw - 1972 - The Agenda-Setting Function of Mass Media.pdf}
}

@online{mcgee23,
  type = {SSRN Scholarly Paper},
  title = {Is {{Chat Gpt Biased Against Conservatives}}? {{An Empirical Study}}},
  shorttitle = {Is {{Chat Gpt Biased Against Conservatives}}?},
  author = {McGee, Robert W.},
  date = {2023-02-15},
  number = {4359405},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4359405},
  url = {https://papers.ssrn.com/abstract=4359405},
  urldate = {2023-11-24},
  abstract = {This paper used Chat GPT to create Irish Limericks. During the creation process, a pattern was observed that seemed to create positive Limericks for liberal politicians and negative Limericks for conservative politicians. Upon identifying this pattern, the sample size was expanded to 80 and some mathematical calculations were made to determine whether the actual results were different from what probability theory would suggest. It was found that, at least in some cases, the AI was biased to favor liberal politicians and disfavor conservatives.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {51 citations (Crossref/DOI) [2024-10-14]},
  file = {/Users/jeremygilbert/Zotero/storage/QNZX3LFB/McGee_2023_Is Chat Gpt Biased Against Conservatives.pdf}
}

@article{meyer_etal20,
  title = {Who {{Gets}} into the {{Papers}}? {{Party Campaign Messages}} and the {{Media}}},
  shorttitle = {Who {{Gets}} into the {{Papers}}?},
  author = {Meyer, Thomas M. and Haselmayer, Martin and Wagner, Markus},
  date = {2020-01},
  journaltitle = {British Journal of Political Science},
  shortjournal = {Brit. J. Polit. Sci.},
  volume = {50},
  number = {1},
  pages = {281--302},
  issn = {0007-1234, 1469-2112},
  doi = {10.1017/S0007123417000400},
  url = {https://www.cambridge.org/core/product/identifier/S0007123417000400/type/journal_article},
  urldate = {2024-12-03},
  abstract = {Parties and politicians want their messages to generate media coverage and thereby reach voters. We examine how attributes related to content and sender affect whether party messages are likely to get media attention. Based on content analyses of 1,613 party press releases and 6,512 media reports in a parliamentary, multiparty context, we suggest that party messages are more likely to make it into the news if they address concerns already important to the media or other parties. Discussing these issues may in particular help opposition parties and lower-profile politicians to get media attention. These results confirm the importance of agenda-setting and gatekeeping, shed light on the potential success of party strategies, and have implications for political fairness and representation.},
  langid = {english},
  keywords = {Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/HPNBIZST/Meyer et al. - 2020 - Who Gets into the Papers Party Campaign Messages and the Media.pdf}
}

@incollection{nadeau_bastien03,
  title = {La communication électorale},
  booktitle = {La communication politique: État des savoirs, enjeux et perspectives},
  author = {Nadeau, Richard and Bastien, Frédérick},
  date = {2003-05-06},
  edition = {1},
  eprint = {10.2307/j.ctv5j01b9},
  eprinttype = {jstor},
  publisher = {Presses de l'Université du Québec},
  doi = {10.2307/j.ctv5j01b9},
  url = {http://www.jstor.org/stable/10.2307/j.ctv5j01b9},
  urldate = {2024-12-03},
  isbn = {978-2-7605-1739-4 978-2-7605-1218-4},
  langid = {french},
  keywords = {Medias effect on parties,Vote seeking},
  file = {/Users/jeremygilbert/Zotero/storage/FIR3IQBC/Gingras - 2003 - La communication politique État des savoirs, enjeux et perspectives.pdf}
}

@article{petrocik96,
  title = {Issue {{Ownership}} in {{Presidential Elections}}, with a 1980 {{Case Study}}},
  author = {Petrocik, John R.},
  date = {1996-08},
  journaltitle = {American Journal of Political Science},
  shortjournal = {American Journal of Political Science},
  volume = {40},
  number = {3},
  eprint = {2111797},
  eprinttype = {jstor},
  pages = {825},
  issn = {00925853},
  doi = {10.2307/2111797},
  url = {https://www.jstor.org/stable/2111797?origin=crossref},
  urldate = {2024-12-03},
  langid = {english},
  keywords = {Issue ownership},
  file = {/Users/jeremygilbert/Zotero/storage/RMUU3GRM/Petrocik - 1996 - Issue Ownership in Presidential Elections, with a 1980 Case Study.pdf}
}

@article{pranckevicius_marcinkevicius17,
  title = {Comparison of {{Naive Bayes}}, {{Random Forest}}, {{Decision Tree}}, {{Support Vector Machines}}, and {{Logistic Regression Classifiers}} for {{Text Reviews Classification}}},
  author = {Pranckevičius, Tomas and Marcinkevičius, Virginijus},
  date = {2017},
  journaltitle = {Baltic Journal of Modern Computing},
  shortjournal = {BJMC},
  volume = {5},
  number = {2},
  issn = {22558950},
  doi = {10.22364/bjmc.2017.5.2.05},
  url = {http://www.bjmc.lu.lv/fileadmin/user_upload/lu_portal/projekti/bjmc/Contents/5_2_05_Pranckevicius.pdf},
  urldate = {2025-02-10},
  abstract = {Today, a largely scalable computing environment provides a possibility of carrying out various data-intensive natural language processing and machine-learning tasks. One of these is text classification with some issues recently investigated by many data scientists. The authors of this paper investigate Naïve Bayes, Random Forest, Decision Tree, Support Vector Machines, and Logistic Regression classifiers implemented in Apache Spark, i.e. the in-memory intensive computing platform. The focus of the paper is on comparing these classifiers by evaluating the classification accuracy, based on the size of training data sets, and the number of n-grams. In experiments, short texts for product-review data from Amazon1 were analyzed.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/C7FZFVLV/Pranckevičius et Marcinkevičius - 2017 - Comparison of Naive Bayes, Random Forest, Decision Tree, Support Vector Machines, and Logistic Regre.pdf}
}

@article{rozado23,
  title = {The {{Political Biases}} of {{ChatGPT}}},
  author = {Rozado, David},
  date = {2023},
  journaltitle = {Social Sciences},
  shortjournal = {Social Sciences},
  volume = {12},
  number = {3},
  pages = {148},
  abstract = {Recent advancements in Large Language Models (LLMs) suggest imminent commercial applications of such AI systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular ChatGPT from OpenAI. The results are consistent across tests; 14 of the 15 instruments diagnose ChatGPT answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, ChatGPT often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical AI systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/FCWA3NBQ/Rozado_2023_The Political Biases of ChatGPT.pdf;/Users/jeremygilbert/Zotero/storage/YCWRR89U/Rozado - 2023 - The Political Biases of ChatGPT.pdf;/Users/jeremygilbert/Zotero/storage/6H9YXGVZ/148.html}
}

@article{salman_al-jawher24,
  title = {Performance {{Comparison}} of {{Support Vector Machines}}, {{AdaBoost}}, and {{Random Forest}} for {{Sentiment Text Analysis}} and {{Classification}}},
  author = {Salman, Ahmed Hussein and Al-Jawher, Waleed Ameen Mahmoud},
  date = {2024-09-01},
  journaltitle = {Journal Port Science Research},
  shortjournal = {J.port.sci.res.},
  volume = {7},
  number = {3},
  pages = {300--311},
  issn = {2616-7441, 2616-6232},
  doi = {10.36371/port.2024.3.8},
  url = {https://jport.co/index.php/jport/article/view/258},
  urldate = {2025-02-10},
  abstract = {In sentiment analysis, text analysis becomes an important process to derive useful information from the unstructured data. In this work, we study the performance of three advanced machine learning algorithms, Support Vector Machines (SVM), Random Forest, and AdaBoost, for a specific sentiment classification task. Each classifier was trained and evaluated on principal metrics such as Area Under the Curve (AUC), Classification Accuracy (CA), F1-Score, Precision, and Recall using the Bag of Words model for feature extraction. Those results show that the Random Forest approach beat both SVM and AdaBoost, with an AUC of 0.988, CA = 0.915, and F1-Score = 0.915 SVM demonstrated moderate performance with an AUC of 0.939 and an F1-Score of 0.845, while AdaBoost exhibited the worst performance in all metrics based on that ensemble model-based classifiers for data change predictions. Random Forest may thus be a powerful machine learning technique to implement for sentiment analysis in text.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/U3AVRLAK/Salman et Al-Jawher - 2024 - Performance Comparison of Support Vector Machines, AdaBoost, and Random Forest for Sentiment Text An.pdf}
}

@article{sevenans_vliegenthart16,
  title = {Political {{Agenda-Setting}} in {{Belgium}} and the {{Netherlands}}: {{The Moderating Role}} of {{Conflict Framing}}},
  author = {Sevenans, Julie and Vliegenthart, Rens},
  date = {2016},
  abstract = {This article investigates the role of conflict framing as a moderator of the political agenda-setting effect. Conflict is at the heart of politics: Political debate arises from political actors taking opposing positions. We hypothesize that conflict framing in media coverage enhances the relevance of the news for politicians, who in turn react more to this news in parliament. We test our expectations by looking at media coverage and parliamentary questions in Belgium (1999-2008) and the Netherlands (1995-2011). Pooled time-series analyses demonstrate that conflict framing indeed matters as it strengthens the “basic” political agenda-setting effect from the media on parliamentary questions.},
  langid = {english},
  keywords = {Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/HV4UPHXB/Sevenans et Vliegenthart - Political Agenda-Setting in Belgium and the Netherlands The Moderating Role of Conflict Framing.pdf}
}

@article{sevenans18,
  title = {How Mass Media Attract Political Elites’ Attention},
  author = {Sevenans, Julie},
  date = {2018-02},
  journaltitle = {European Journal of Political Research},
  shortjournal = {European J Political Res},
  volume = {57},
  number = {1},
  pages = {153--170},
  issn = {0304-4130, 1475-6765},
  doi = {10.1111/1475-6765.12220},
  url = {https://ejpr.onlinelibrary.wiley.com/doi/10.1111/1475-6765.12220},
  urldate = {2024-09-25},
  abstract = {Political agenda-setting research has shown that policymakers are responsive vis-à-vis media priorities. The mechanisms behind this effect have remained understudied so far, though. In particular, agenda-setting scholars have difficulties determining to what extent politicians react to media coverage purely because of the information it contains (information effect), and to what extent the effect is driven not by what the media say but by the fact that certain information is in the media (media channel effect), which is valued for its own sake—for instance because media coverage is considered to be a reflection of public opinion. By means of a survey-embedded experiment with Belgian, Canadian and Israeli political elites (N = 410), this paper tests whether the mere fact that an issue is covered by the news media causes politicians to pay attention to this issue. It shows that a piece of information gets more attention from politicians when it comes via the media than an identical piece of information coming via a personal e-mail. This effect occurs largely across the board: it is not dependent on individual politician characteristics.},
  langid = {english},
  keywords = {Medias effect on parties},
  file = {/Users/jeremygilbert/Zotero/storage/TI2HB3K4/Sevenans - 2018 - How mass media attract political elites’ attention.pdf}
}

@article{shapiro_etal20,
  title = {Measuring {{News Sentiment}}},
  author = {Shapiro, Adam H. and Sudhof, Moritz and {Stanford University} and Wilson, Daniel and {Federal Reserve Bank of San Francisco}},
  date = {2020-03-13},
  journaltitle = {Federal Reserve Bank of San Francisco, Working Paper Series},
  shortjournal = {ERWP},
  pages = {01--49},
  doi = {10.24148/wp2017-01},
  url = {https://www.frbsf.org/research-and-insights/publications/working-papers/2020/03/measuring-news-sentiment/},
  urldate = {2024-12-19},
  abstract = {This paper demonstrates state-of-the-art text sentiment analysis tools while developing a new time-series measure of economic sentiment derived from economic and financial newspaper articles from January 1980 to April 2015. We compare the predictive accuracy of a large set of sentiment analysis models using a sample of articles that have been rated by humans on a positivity/negativity scale. The results highlight the gains from combining existing lexicons and from accounting for negation. We also generate our own sentiment-scoring model, which includes a new lexicon built specifically to capture the sentiment in economic news articles. This model is shown to have better predictive accuracy than existing, “off-the-shelf”, models. Lastly, we provide two applications to the economic research on sentiment. First, we show that daily news sentiment is predictive of movements of survey-based measures of consumer sentiment. Second, motivated by Barsky and Sims (2012), we estimate the impulse responses of macroeconomic variables to sentiment shocks, finding that positive sentiment shocks increase consumption, output, and interest rates and dampen inflation.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/CRC6AZLF/Federal Reserve Bank of San Francisco et al. - 2020 - Measuring News Sentiment.pdf}
}

@article{shyrokykh_etal23,
  title = {Short Text Classification with Machine Learning in the Social Sciences: {{The}} Case of Climate Change on {{Twitter}}},
  shorttitle = {Short Text Classification with Machine Learning in the Social Sciences},
  author = {Shyrokykh, Karina and Girnyk, Max and Dellmuth, Lisa},
  editor = {Bacanin, Nebojsa},
  date = {2023-09-29},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {18},
  number = {9},
  pages = {e0290762},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0290762},
  url = {https://dx.plos.org/10.1371/journal.pone.0290762},
  urldate = {2025-02-10},
  abstract = {To analyse large numbers of texts, social science researchers are increasingly confronting the challenge of text classification. When manual labeling is not possible and researchers have to find automatized ways to classify texts, computer science provides a useful toolbox of machine-learning methods whose performance remains understudied in the social sciences. In this article, we compare the performance of the most widely used text classifiers by applying them to a typical research scenario in social science research: a relatively small labeled dataset with infrequent occurrence of categories of interest, which is a part of a large unlabeled dataset. As an example case, we look at Twitter communication regarding climate change, a topic of increasing scholarly interest in interdisciplinary social science research. Using a novel dataset including 5,750 tweets from various international organizations regarding the highly ambiguous concept of climate change, we evaluate the performance of methods in automatically classifying tweets based on whether they are about climate change or not. In this context, we highlight two main findings. First, supervised machine-learning methods perform better than state-of-the-art lexicons, in particular as class balance increases. Second, traditional machine-learning methods, such as logistic regression and random forest, perform similarly to sophisticated deep-learning methods, whilst requiring much less training time and computational resources. The results have important implications for the analysis of short texts in social science research.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/VDWCC8Y4/Shyrokykh et al. - 2023 - Short text classification with machine learning in the social sciences The case of climate change o.pdf}
}

@article{slapin_proksch08a,
  title = {A {{Scaling Model}} for {{Estimating Time}}‐{{Series Party Positions}} from {{Texts}}},
  author = {Slapin, Jonathan B. and Proksch, Sven‐Oliver},
  date = {2008-07},
  journaltitle = {American Journal of Political Science},
  shortjournal = {American J Political Sci},
  volume = {52},
  number = {3},
  pages = {705--722},
  publisher = {Wiley},
  issn = {0092-5853, 1540-5907},
  doi = {10.1111/j.1540-5907.2008.00338.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1540-5907.2008.00338.x},
  urldate = {2024-09-16},
  abstract = {Recent advances in computational content analysis have provided scholars promising new ways for estimating party positions. However, existing text‐based methods face challenges in producing valid and reliable time‐series data. This article proposes a scaling algorithm called WORDFISH to estimate policy positions based on word frequencies in texts. The technique allows researchers to locate parties in one or multiple elections. We demonstrate the algorithm by estimating the positions of German political parties from 1990 to 2005 using word frequencies in party manifestos. The extracted positions reflect changes in the party system more accurately than existing time‐series estimates. In addition, the method allows researchers to examine which words are important for placing parties on the left and on the right. We find that words with strong political connotations are the best discriminators between parties. Finally, a series of robustness checks demonstrate that the estimated positions are insensitive to distributional assumptions and document selection.},
  langid = {english},
  keywords = {Textual analysis},
  file = {/Users/jeremygilbert/Zotero/storage/D5NSZTUD/Slapin et Proksch - 2008 - A Scaling Model for Estimating Time‐Series Party Positions from Texts.pdf}
}

@book{soroka02,
  title = {Agenda-Setting Dynamics in {{Canada}}},
  author = {Soroka, Stuart},
  date = {2002},
  publisher = {UBC press},
  keywords = {Political agenda-setting}
}

@article{stromback_vanaelst13,
  title = {Why Political Parties Adapt to the Media: {{Exploring}} the Fourth Dimension of Mediatization},
  shorttitle = {Why Political Parties Adapt to the Media},
  author = {Strömbäck, Jesper and Van Aelst, Peter},
  date = {2013-06},
  journaltitle = {International Communication Gazette},
  shortjournal = {International Communication Gazette},
  volume = {75},
  number = {4},
  pages = {341--358},
  issn = {1748-0485, 1748-0493},
  doi = {10.1177/1748048513482266},
  url = {https://journals.sagepub.com/doi/10.1177/1748048513482266},
  urldate = {2024-12-03},
  abstract = {One key concept in research on how the media influence political processes is mediatization, which denotes a long-term process through which the media have become increasingly independent from politics and through which political actors and institutions have become increasingly dependent on the media. While it is often claimed that politics has become increasingly mediatized, the process of mediatization has not yet been properly addressed in the literature. Against this background, and based on the literature on mediatization and strategic party behavior, the purpose of this article is to theoretically explore the processes through which political parties become mediatized, and to suggest a model of media adaptation by political parties.},
  langid = {english},
  keywords = {Medias effect on parties,Parties effect on media},
  file = {/Users/jeremygilbert/Zotero/storage/XZFBMDKB/Strömbäck et Van Aelst - 2013 - Why political parties adapt to the media Exploring the fourth dimension of mediatization.pdf}
}

@article{stromback08,
  title = {Four {{Phases}} of {{Mediatization}}: {{An Analysis}} of the {{Mediatization}} of {{Politics}}},
  shorttitle = {Four {{Phases}} of {{Mediatization}}},
  author = {Strömbäck, Jesper},
  date = {2008-07},
  journaltitle = {The International Journal of Press/Politics},
  shortjournal = {The International Journal of Press/Politics},
  volume = {13},
  number = {3},
  pages = {228--246},
  issn = {1940-1612, 1940-1620},
  doi = {10.1177/1940161208319097},
  url = {https://journals.sagepub.com/doi/10.1177/1940161208319097},
  urldate = {2024-12-03},
  abstract = {Two concepts that have been used to describe the changes with regards to media and politics during the last fifty years are the concepts of mediation and mediatization . However, both these concepts are used more often than they are properly defined. Moreover, there is a lack of analysis of the process of mediatization, although the concept as such denotes a process.Thus the purpose of this article is to analyze the concepts of mediated and mediatized politics from a process-oriented perspective. The article argues that mediatization is a multidimensional and inherently process-oriented concept and that it is possible to make a distinction between four phases of mediatization. Each of these phases is analyzed.The conclusion is that as politics becomes increasingly mediatized, the important question no longer is related to the independence of the media from politics and society. The important question becomes the independence of politics and society from the media.},
  langid = {english},
  keywords = {Medias effect on parties},
  file = {/Users/jeremygilbert/Zotero/storage/EMLYTQ7X/Strömbäck - 2008 - Four Phases of Mediatization An Analysis of the Mediatization of Politics.pdf}
}

@book{surowiecki05,
  title = {The {{Wisdom}} of {{Crowds}}},
  author = {Surowiecki, James},
  date = {2005-08-16},
  eprint = {_t2KDQAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Knopf Doubleday Publishing Group},
  abstract = {In this fascinating book, New Yorker business columnist James Surowiecki explores a deceptively simple idea: Large groups of people are smarter than an elite few, no matter how brilliant—better at solving problems, fostering innovation, coming to wise decisions, even predicting the future.~With boundless erudition and in delightfully clear prose, Surowiecki ranges across fields as diverse as popular culture, psychology, ant biology, behavioral economics, artificial intelligence, military history, and politics to show how this simple idea offers important lessons for how we live our lives, select our leaders, run our companies, and think about our world.},
  isbn = {978-0-385-72170-7},
  langid = {english},
  pagetotal = {337},
  keywords = {Business & Economics / Consumer Behavior,Business & Economics / Economic History,Social Science / Sociology / Social Theory}
}

@article{talboy_fuller23,
  title = {Challenging the Appearance of Machine Intelligence: {{Cognitive}} Bias in {{LLMs}} and {{Best Practices}} for {{Adoption}}},
  author = {Talboy, Alaina N. and Fuller, Elizabeth},
  date = {2023},
  journaltitle = {arXiv preprint arXiv:2304.01358.},
  keywords = {AI ethics yeah!},
  file = {/Users/jeremygilbert/Zotero/storage/VTRX8R5K/2304.01358v3.pdf}
}

@online{tornberg23,
  title = {{{ChatGPT-4 Outperforms Experts}} and {{Crowd Workers}} in {{Annotating Political Twitter Messages}} with {{Zero-Shot Learning}}},
  author = {Törnberg, Petter},
  date = {2023-04-13},
  eprint = {2304.06588},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.06588},
  url = {http://arxiv.org/abs/2304.06588},
  urldate = {2024-12-09},
  abstract = {This paper assesses the accuracy, reliability and bias of the Large Language Model (LLM) ChatGPT-4 on the text analysis task of classifying the political affiliation of a Twitter poster based on the content of a tweet. The LLM is compared to manual annotation by both expert classifiers and crowd workers, generally considered the gold standard for such tasks. We use Twitter messages from United States politicians during the 2020 election, providing a ground truth against which to measure accuracy. The paper finds that ChatGPT-4 has achieves higher accuracy, higher reliability, and equal or lower bias than the human classifiers. The LLM is able to correctly annotate messages that require reasoning on the basis of contextual knowledge, and inferences around the author's intentions - traditionally seen as uniquely human abilities. These findings suggest that LLM will have substantial impact on the use of textual data in the social sciences, by enabling interpretive research at a scale.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Social and Information Networks},
  file = {/Users/jeremygilbert/Zotero/storage/JMBBZUCM/Törnberg - 2023 - ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-S.pdf}
}

@article{tremblay-antoine_etal24,
  title = {An Open Window into Politics: {{A}} Structured Database of Plenary Sessions of the {{European Parliament}}},
  shorttitle = {An Open Window into Politics},
  author = {Tremblay-Antoine, Camille and Jacob, Steve and Dufresne, Yannick and Poncet, Patrick and Dinan, Shannon},
  date = {2024-09},
  journaltitle = {European Union Politics},
  shortjournal = {European Union Politics},
  volume = {25},
  number = {3},
  pages = {605--622},
  issn = {1465-1165, 1741-2757},
  doi = {10.1177/14651165241239637},
  url = {https://journals.sagepub.com/doi/10.1177/14651165241239637},
  urldate = {2024-12-19},
  abstract = {The uniqueness of the European Parliament, as well as the magnitude of impact its decisions wield over member states, are elements that capture researchers’ attention. However, several of this institution’s particularities have made broad analysis of the textual content it produces difficult. This research note presents Vitrine Démocratique, a new, publicly accessible, and centralized database structuring interventions made in the European Parliament starting in 2014, both in their original languages and translated to English. The process by which this high-velocity database was created is presented, as well as a descriptive overview of the contents of this data source, which is continuously updated on a daily basis.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/FY4DWJCZ/Tremblay-Antoine et al. - 2024 - An open window into politics A structured database of plenary sessions of the European Parliament.pdf}
}

@incollection{vanaelst_etal14,
  title = {Mediatization and Political Agenda-Setting: Changing Issue Priorities?},
  booktitle = {Mediatization of Politics: {{Understanding}} the Transformation of {{Western}} Democracies},
  author = {Van Aelst, Peter and Thesen, Gunnar and Walgrave, Stefaan and Vliegenthart, Rens},
  date = {2014},
  pages = {200--220},
  publisher = {Palgrave Macmillan UK},
  location = {London}
}

@article{vanaelst_walgrave16,
  title = {Political Agenda Setting by the Mass Media: {{Ten}} Years of Research, 2005--2015},
  author = {Van Aelst, Peter and Walgrave, Stefaan},
  date = {2016},
  journaltitle = {Handbook of public policy agenda setting},
  pages = {157--179},
  keywords = {Political agenda-setting}
}

@article{vanatteveldt_etal21,
  title = {The {{Validity}} of {{Sentiment Analysis}}: {{Comparing Manual Annotation}}, {{Crowd-Coding}}, {{Dictionary Approaches}}, and {{Machine Learning Algorithms}}},
  shorttitle = {The {{Validity}} of {{Sentiment Analysis}}},
  author = {Van Atteveldt, Wouter and Van Der Velden, Mariken A. C. G. and Boukes, Mark},
  date = {2021-04-03},
  journaltitle = {Communication Methods and Measures},
  shortjournal = {Communication Methods and Measures},
  volume = {15},
  number = {2},
  pages = {121--140},
  issn = {1931-2458, 1931-2466},
  doi = {10.1080/19312458.2020.1869198},
  url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2020.1869198},
  urldate = {2024-12-09},
  abstract = {Sentiment is central to many studies of communication science, from negativity and polarization in political communication to analyzing product reviews and social media comments in other sub-fields. This study provides an exhaustive comparison of sentiment analysis methods, using a validation set of Dutch economic headlines to compare the performance of manual annotation, crowd coding, numerous dictionaries and machine learning using both traditional and deep learning algorithms. The three main conclusions of this article are that: (1) The best performance is still attained with trained human or crowd coding; (2) None of the used dictionaries come close to acceptable levels of validity; and (3) machine learning, especially deep learning, substantially outperforms dictionary-based methods but falls short of human performance. From these findings, we stress the importance of always validating automatic text analysis methods before usage. Moreover, we provide a recommended step-bystep approach for (automated) text analysis projects to ensure both efficiency and validity.},
  langid = {english},
  keywords = {tone dictionnary},
  file = {/Users/jeremygilbert/Zotero/storage/DD9QCZD5/Van Atteveldt et al. - 2021 - The Validity of Sentiment Analysis Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches.pdf}
}

@article{vandenbroek23,
  title = {{{ChatGPT}}’s Left-Leaning Liberal Bias},
  author = {Van den Broek, Merel},
  date = {2023},
  journaltitle = {University of Leiden},
  url = {https://www.universiteitleiden.nl/binaries/content/assets/algemeen/bb-scm/nieuws/political_bias_in_chatgpt.pdf},
  urldate = {2023-11-24},
  keywords = {Biais gauche,Biais liberal,GPT Suck},
  file = {/Users/jeremygilbert/Zotero/storage/LKZ86Y3U/van den Broek_2023_ChatGPT’s left-leaning liberal bias.pdf}
}

@article{vaswani_etal17,
  title = {Attention Is {{All}} You {{Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  date = {2017},
  journaltitle = {Advances in Neural Information Processing Systems},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/53LM7SA5/Vaswani et al. - Attention is All you Need.pdf}
}

@article{vliegenthart_etal16,
  title = {Do the Media Set the Parliamentary Agenda? {{A}} Comparative Study in Seven Countries},
  shorttitle = {Do the Media Set the Parliamentary Agenda?},
  author = {Vliegenthart, Rens and Walgrave, Stefaan and Baumgartner, Frank R. and Bevan, Shaun and Breunig, Christian and Brouard, Sylvain and Bonafont, Laura Chaqués and Grossman, Emiliano and Jennings, Will and Mortensen, Peter B. and Palau, Anna M. and Sciarini, Pascal and Tresch, Anke},
  date = {2016-05},
  journaltitle = {European Journal of Political Research},
  shortjournal = {European J Political Res},
  volume = {55},
  number = {2},
  pages = {283--301},
  issn = {0304-4130, 1475-6765},
  doi = {10.1111/1475-6765.12134},
  url = {https://ejpr.onlinelibrary.wiley.com/doi/10.1111/1475-6765.12134},
  urldate = {2024-09-25},
  abstract = {A growing body of work has examined the relationship between media and politics from an agenda-setting perspective: Is attention for issues initiated by political elites with the media following suit, or is the reverse relation stronger? A long series of single-country studies has suggested a number of general agenda-setting patterns but these have never been confirmed in a comparative approach. In a comparative, longitudinal design including comparable media and politics evidence for seven European countries (Belgium, Denmark, France, Netherlands, Spain, Switzerland and the United Kingdom), this study highlights a number of generic patterns. Additionally, it shows how the political system matters. Overall, the media are a stronger inspirer of political action in countries with single-party governments compared to those with multiple-party governments for opposition parties. But, government parties are more reactive to media under multiparty governments.},
  langid = {english},
  keywords = {Medias,Opposition vs gov,Parties effect on media,Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/VDRQX2A9/Vliegenthart et al. - 2016 - Do the media set the parliamentary agenda A comparative study in seven countries.pdf}
}

@article{vliegenthart_walgrave11,
  title = {When the Media Matter for Politics: {{Partisan}} Moderators of the Mass Media’s Agenda-Setting Influence on Parliament in {{Belgium}}},
  shorttitle = {When the Media Matter for Politics},
  author = {Vliegenthart, Rens and Walgrave, Stefaan},
  date = {2011-05},
  journaltitle = {Party Politics},
  volume = {17},
  number = {3},
  pages = {321--342},
  publisher = {SAGE Publications},
  issn = {1354-0688, 1460-3683},
  doi = {10.1177/1354068810366016},
  url = {https://journals.sagepub.com/doi/10.1177/1354068810366016},
  urldate = {2024-09-17},
  abstract = {In this study, we investigate which factors moderate the agenda-setting influence of the mass media on the Belgian parliament during the period 1993–2000. Based on elaborate codings of the media, parliamentary questions and interpellations, party manifestos, government agreements and ministerial meetings, we employ a multi-level time-series model. The results indicate that especially party characteristics (party size, incumbent or opposition party, issue ownership) and the government agenda influence the dependency of parliament on media coverage. Furthermore, we find an increase in the extent of media influence through time, suggesting an increasing presence of ‘media logic’ in the behaviour of Belgian MPs. Irrespective of all those contingent factors, the mass media determine the Belgian parliamentary agenda to a considerable degree.},
  langid = {english},
  keywords = {Opposition vs gov,Parties adaptation on media},
  file = {/Users/jeremygilbert/Zotero/storage/NXHK73R2/Vliegenthart et Walgrave - 2011 - When the media matter for politics Partisan moderators of the mass media’s agenda-setting influence.pdf}
}

@article{walgrave_etal08,
  title = {The {{Mass Media}}'s {{Political Agenda-Setting Power}}: {{A Longitudinal Analysis}} of {{Media}}, {{Parliament}}, and {{Government}} in {{Belgium}} (1993 to 2000)},
  shorttitle = {The {{Mass Media}}'s {{Political Agenda-Setting Power}}},
  author = {Walgrave, Stefaan and Soroka, Stuart and Nuytemans, Michiel},
  date = {2008-06},
  journaltitle = {Comparative Political Studies},
  shortjournal = {Comparative Political Studies},
  volume = {41},
  number = {6},
  pages = {814--836},
  issn = {0010-4140, 1552-3829},
  doi = {10.1177/0010414006299098},
  url = {https://journals.sagepub.com/doi/10.1177/0010414006299098},
  urldate = {2024-09-25},
  abstract = {Do mass media determine or codetermine the political agenda? Available answers on this question are mixed and contradictory. Results vary in terms of the type of political agenda under scrutiny, the kind of media taken into account, and the type of issues covered. This article enhances knowledge of the media's political agenda-setting power by addressing each of these topics, drawing on extensive longitudinal measures of issue attentiveness in media, Parliament, and government in Belgium in the 1990s. Relying on time-series, cross-section analyses, the authors ascertain that although Belgium is characterized by a closed political system, the media do to some extent determine the agenda of Parliament and government. There is systematic variation in media effects, however. Newspapers exert more influence than does television, Parliament is somewhat more likely to follow media than government, and media effects are larger for certain issues (law and order, environment) than for others (foreign policy, economic issues).},
  langid = {english},
  keywords = {Electoral periods,Political agenda-setting},
  file = {/Users/jeremygilbert/Zotero/storage/C2QV2IRT/Walgrave et al. - 2008 - The Mass Media's Political Agenda-Setting Power A Longitudinal Analysis of Media, Parliament, and G.pdf}
}

@article{walgrave_vanaelst06,
  title = {The {{Contingency}} of the {{Mass Media}}'s {{Political Agenda Setting Power}}: {{Toward}} a {{Preliminary Theory}}},
  shorttitle = {The {{Contingency}} of the {{Mass Media}}'s {{Political Agenda Setting Power}}},
  author = {Walgrave, Stefaan and Van Aelst, Peter},
  date = {2006-03-01},
  journaltitle = {Journal of Communication},
  volume = {56},
  number = {1},
  pages = {88--109},
  publisher = {Oxford University Press (OUP)},
  issn = {0021-9916, 1460-2466},
  doi = {10.1111/j.1460-2466.2006.00005.x},
  url = {https://academic.oup.com/joc/article/56/1/88-109/4102573},
  urldate = {2024-09-17},
  langid = {english},
  keywords = {Medias effect on parties},
  file = {/Users/jeremygilbert/Zotero/storage/IB5JC7SN/Walgrave et Van Aelst - 2006 - The Contingency of the Mass Media's Political Agenda Setting Power Toward a Preliminary Theory.pdf}
}

@inproceedings{wang_etal06,
  title = {An {{Optimal SVM-Based Text Classification Algorithm}}},
  booktitle = {2006 {{International Conference}} on {{Machine Learning}} and {{Cybernetics}}},
  author = {Wang, Zi-qiang and Sun, Xia and Zhang, De-xian and Li, Xin},
  date = {2006-08},
  pages = {1378--1381},
  issn = {2160-1348},
  doi = {10.1109/ICMLC.2006.258708},
  url = {https://ieeexplore.ieee.org/document/4028279/?arnumber=4028279},
  urldate = {2025-02-10},
  abstract = {The goal of a text classification system is to determine whether a given document belongs to which of the predefined categories. An optimal SVM algorithm for text classification via multiple optimal strategies is proposed in this paper. The experimental results indicate that the proposed optimal classification algorithm yields much better performance than other conventional algorithms},
  eventtitle = {2006 {{International Conference}} on {{Machine Learning}} and {{Cybernetics}}},
  keywords = {Classification algorithms,Electronic mail,Machine learning algorithms,optimal strategies,Organizing,Statistical analysis,Sun,Support vector machine classification,Support vector machines,SVM,Text categorization,Text classification,Web sites},
  file = {/Users/jeremygilbert/Zotero/storage/XYDS3UGH/Wang et al. - 2006 - An Optimal SVM-Based Text Classification Algorithm.pdf;/Users/jeremygilbert/Zotero/storage/DY9J23MH/4028279.html}
}

@article{welbers_etal17,
  title = {Text {{Analysis}} in {{R}}},
  author = {Welbers, Kasper and Van Atteveldt, Wouter and Benoit, Kenneth},
  date = {2017-10-02},
  journaltitle = {Communication Methods and Measures},
  shortjournal = {Communication Methods and Measures},
  volume = {11},
  number = {4},
  pages = {245--265},
  issn = {1931-2458, 1931-2466},
  doi = {10.1080/19312458.2017.1387238},
  url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2017.1387238},
  urldate = {2024-11-08},
  abstract = {Computational text analysis has become an exciting research field with many applications in communication research. It can be a difficult method to apply, however, because it requires knowledge of various techniques, and the software required to perform most of these techniques is not readily available in common statistical software packages. In this teacher’s corner, we address these barriers by providing an overview of general steps and operations in a computational text analysis project, and demonstrate how each step can be performed using the R statistical software. As a popular open-source platform, R has an extensive user community that develops and maintains a wide range of text analysis packages. We show that these packages make it easy to perform advanced text analytics.},
  langid = {english},
  keywords = {Textual analysis},
  file = {/Users/jeremygilbert/Zotero/storage/M34EG9T5/Welbers et al. - 2017 - Text Analysis in R.pdf}
}

@article{widmann_wich23,
  title = {Creating and {{Comparing Dictionary}}, {{Word Embedding}}, and {{Transformer-Based Models}} to {{Measure Discrete Emotions}} in {{German Political Text}}},
  author = {Widmann, Tobias and Wich, Maximilian},
  date = {2023-10},
  journaltitle = {Political Analysis},
  shortjournal = {Polit. Anal.},
  volume = {31},
  number = {4},
  pages = {626--641},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2022.15},
  url = {https://www.cambridge.org/core/product/identifier/S1047198722000158/type/journal_article},
  urldate = {2024-12-09},
  abstract = {Previous research on emotional language relied heavily on off-the-shelf sentiment dictionaries that focus on negative and positive tone. These dictionaries are often tailored to nonpolitical domains and use bag-of-words approaches which come with a series of disadvantages. This paper creates, validates, and compares the performance of (1) a novel emotional dictionary specifically for political text, (2) locally trained word embedding models combined with simple neural network classifiers, and (3) transformer-based models which overcome limitations of the dictionary approach. All tools can measure emotional appeals associated with eight discrete emotions. The different approaches are validated on different sets of crowdcoded sentences. Encouragingly, the results highlight the strengths of novel transformer-based models, which come with easily available pretrained language models. Furthermore, all customized approaches outperform widely used off-the-shelf dictionaries in measuring emotional language in German political discourse.},
  langid = {english},
  file = {/Users/jeremygilbert/Zotero/storage/XDBJ93S3/Widmann et Wich - 2023 - Creating and Comparing Dictionary, Word Embedding, and Transformer-Based Models to Measure Discrete.pdf}
}

@article{young_soroka12,
  title = {Affective {{News}}: {{The Automated Coding}} of {{Sentiment}} in {{Political Texts}}},
  shorttitle = {Affective {{News}}},
  author = {Young, Lori and Soroka, Stuart},
  date = {2012-04},
  journaltitle = {Political Communication},
  shortjournal = {Political Communication},
  volume = {29},
  number = {2},
  pages = {205--231},
  issn = {1058-4609, 1091-7675},
  doi = {10.1080/10584609.2012.671234},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10584609.2012.671234},
  urldate = {2024-12-09},
  abstract = {An increasing number of studies in political communication focus on the “sentiment” or “tone” of news content, political speeches, or advertisements. This growing interest in measuring sentiment coincides with a dramatic increase in the volume of digitized information. Computer automation has a great deal of potential in this new media environment. The objective here is to outline and validate a new automated measurement instrument for sentiment analysis in political texts. Our instrument uses a dictionary-based approach consisting of a simple word count of the frequency of keywords in a text from a predefined dictionary. The design of the freely available Lexicoder Sentiment Dictionary (LSD) is discussed in detail here. The dictionary is tested against a body of human-coded news content, and the resulting codes are also compared to results from nine existing content-analytic dictionaries. Analyses suggest that the LSD produces results that are more systematically related to human coding than are results based on the other available dictionaries. The LSD is thus a useful starting point for a revived discussion about dictionary construction and validation in sentiment analysis for political communication.},
  langid = {english},
  keywords = {tone dictionnary},
  file = {/Users/jeremygilbert/Zotero/storage/JAEP527U/Young et Soroka - 2012 - Affective News The Automated Coding of Sentiment in Political Texts.pdf}
}

@article{zack_etal23,
  title = {Coding {{Inequity}}: {{Assessing GPT-4}}'s {{Potential}} for {{Perpetuating Racial}} and {{Gender Biases}} in {{Healthcare}}},
  shorttitle = {Coding {{Inequity}}},
  author = {Zack, Travis and Lehman, Eric and Suzgun, Mirac and Rodriguez, Jorge A. and Celi, Leo Anthony and Gichoya, Judy and Jurafsky, Dan and Szolovits, Peter and Bates, David W. and Abdulnour, Raja-Elie E.},
  date = {2023},
  journaltitle = {medRxiv},
  pages = {2023--07},
  publisher = {Cold Spring Harbor Laboratory Press},
  url = {https://www.medrxiv.org/content/10.1101/2023.07.13.23292577.abstract},
  urldate = {2023-11-24},
  file = {/Users/jeremygilbert/Zotero/storage/7KX3QTYN/Zack et al_2023_Coding Inequity.pdf}
}

@book{zaller92a,
  title = {The {{Nature}} and {{Origins}} of {{Mass Opinion}}},
  author = {Zaller, John},
  date = {1992-08-28},
  eprint = {83yNzu6toisC},
  eprinttype = {googlebooks},
  publisher = {Cambridge University Press},
  abstract = {In this 1992 book John Zaller develops a comprehensive theory to explain how people acquire political information from elites and the mass media and convert it into political preferences. Using numerous specific examples, Zaller applies this theory to the dynamics of public opinion on a broad range of subjects, including domestic and foreign policy, trust in government, racial equality, and presidential approval, as well as voting behaviour in U.S. House, Senate, and presidential elections. The thoery is constructed from four basic premises. The first is that individuals differ substantially in their attention to politics and therefore in their exposure to elite sources of political information. The second is that people react critically to political communication only to the extent that they are knowledgeable about political affairs. The third is that people rarely have fixed attitudes on specific issues; rather, they construct 'preference statements' on the fly as they confront each issue raised. The fourth is that, in constructing these statements, people make the greatest use of ideas that are, for various reasons, the most immediately salient to them. Zaller emphasizes the role of political elites in establishing the terms of political discourse in the mass media and the powerful effect of this framing of issues on the dynamics of mass opinion on any given issue over time.},
  isbn = {978-0-521-40786-1},
  langid = {english},
  pagetotal = {388},
  keywords = {Political Science / General,Political Science / Political Process / General,Political Science / Public Opinion Polling,Psychology / General,Psychology / Social Psychology,Social Science / General,Social Science / Sociology / General}
}

@online{zhang_etal24,
  title = {Pushing {{The Limit}} of {{LLM Capacity}} for {{Text Classification}}},
  author = {Zhang, Yazhou and Wang, Mengyao and Ren, Chenyu and Li, Qiuchi and Tiwari, Prayag and Wang, Benyou and Qin, Jing},
  date = {2024-02-16},
  eprint = {2402.07470},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.07470},
  url = {http://arxiv.org/abs/2402.07470},
  urldate = {2024-12-09},
  abstract = {The value of text classification’s future research has encountered challenges and uncertainties, due to the extraordinary efficacy demonstrated by large language models (LLMs) across numerous downstream NLP tasks. In this era of open-ended language modeling, where task boundaries are gradually fading, an urgent question emerges: have we made significant progress in text classification with the full benefit of LLMs? To answer this question, we propose RGPT, an adaptive boosting framework tailored to produce a specialized text classification LLM by recurrently ensembling a pool of strong base learners. The base learners are constructed by adaptively adjusting the distribution of training samples and iteratively fine-tuning LLMs with them. Such base learners are then ensembled to be a specialized text classification LLM, by recurrently incorporating the historical predictions from the previous learners. Through a comprehensive empirical comparison, we show that RGPT significantly outperforms 8 SOTA PLMs and 7 SOTA LLMs on four benchmarks by 1.36\% on average. Further evaluation experiments reveal a clear superiority of RGPT over average human classification performance1.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/jeremygilbert/Zotero/storage/XMZ6SK7L/Zhang et al. - 2024 - Pushing The Limit of LLM Capacity for Text Classification.pdf}
}

@online{zhuo_etal23,
  title = {Red Teaming {{ChatGPT}} via {{Jailbreaking}}: {{Bias}}, {{Robustness}}, {{Reliability}} and {{Toxicity}}},
  shorttitle = {Red Teaming {{ChatGPT}} via {{Jailbreaking}}},
  author = {Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  date = {2023-05-29},
  eprint = {2301.12867},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.12867},
  url = {http://arxiv.org/abs/2301.12867},
  urldate = {2025-03-16},
  abstract = {Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language models (LLMs) have significantly impacted businesses such as report summarization software and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is little systematic examination and user study of the risks and harmful behaviors of current LLM usage. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method called “red teaming” on OpenAI’s ChatGPT1 to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) Bias 2) Reliability 3) Robustness 4) Toxicity. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on AI ethics and harmal behaviors of ChatGPT, as well as future problems and practical design considerations for responsible LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {AI ethics yeah!,Computer Science - Computation and Language,Computer Science - Software Engineering},
  file = {/Users/jeremygilbert/Zotero/storage/RILR554Y/Zhuo et al. - 2023 - Red teaming ChatGPT via Jailbreaking Bias, Robustness, Reliability and Toxicity.pdf}
}
